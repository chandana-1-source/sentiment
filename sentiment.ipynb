{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.models import Sequential"
      ],
      "metadata": {
        "id": "pqkllQiVnU-M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/content/drive/MyDrive/heart.csv\")"
      ],
      "metadata": {
        "id": "8HT3ZG8-nVmZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "IR76yXp0n8HU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "9YUYayzNoCBU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "null_values = df.isnull().sum()\n",
        "print(\"Null values in the entire Data:\")\n",
        "print(null_values)"
      ],
      "metadata": {
        "id": "GSzweXi_oIHE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.dropna(inplace=True)\n"
      ],
      "metadata": {
        "id": "2cF_KJznoO9B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "null_values = df.isnull().sum()\n",
        "null_values"
      ],
      "metadata": {
        "id": "xYwzD0NeoTPN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop_duplicates(inplace=True)\n"
      ],
      "metadata": {
        "id": "o_e5EQh6oYFP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "\n",
        "# Convert the 'trtbps' column to strings before applying string methods\n",
        "df['trtbps'] = df['trtbps'].astype(str)\n",
        "\n",
        "df['trtbps'] = df['trtbps'].apply(lambda x: x.lower())\n",
        "df['trtbps'] = df['trtbps'].apply(lambda x: x.translate(str.maketrans('', '', string.punctuation)))"
      ],
      "metadata": {
        "id": "f96iXo1jCSAS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['trtbps']"
      ],
      "metadata": {
        "id": "BXKnxhFhtT2F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "# Assuming 'df' is your Data containing text data\n",
        "text_data = df['trtbps']\n",
        "vectorizer = CountVectorizer()\n",
        "feature_matrix = vectorizer.fit_transform(text_data)\n",
        "feature_names = vectorizer.get_feature_names_out()"
      ],
      "metadata": {
        "id": "7GawTg1atYzn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature_names"
      ],
      "metadata": {
        "id": "PnPlxpVVtef1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn.feature_extraction.text as text\n",
        "count_vectorizer = text.CountVectorizer()"
      ],
      "metadata": {
        "id": "AInNmum7tlJ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "count_vectorizer.fit(df.trtbps)"
      ],
      "metadata": {
        "id": "F-t2ZsMrtroc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_features = count_vectorizer.transform(df.trtbps)"
      ],
      "metadata": {
        "id": "ZBMnkXoQt13J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "density = (data_features.getnnz() * 100) / (data_features.shape[0] * data_features.shape[1])\n",
        "print(\"Density of the matrix:\", density)\n",
        "\n"
      ],
      "metadata": {
        "id": "stqD7L_Dt8j0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature_counts = df['trtbps'].value_counts()\n",
        "feature_counts"
      ],
      "metadata": {
        "id": "iU7BttJLutN0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Assuming 'vectorizer' and 'data_features' are already defined\n",
        "features = vectorizer.get_feature_names_out()  # Replace with the variable that holds feature names\n",
        "features_counts = np.sum(data_features.toarray(), axis=0)\n",
        "features_counts_df = pd.DataFrame({'features': features, 'counts': features_counts})\n",
        "\n"
      ],
      "metadata": {
        "id": "muqG9Pp8u0Ti"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "count_of_single_occurrences = len(features_counts_df[features_counts_df['counts'] == 1])\n",
        "count_of_single_occurrences\n"
      ],
      "metadata": {
        "id": "JHuVXFBwvYit"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "count_vectorizer = CountVectorizer(max_features=10000)\n",
        "feature_vector = count_vectorizer.fit_transform(df['trtbps'])\n",
        "features = count_vectorizer.get_feature_names_out()\n",
        "data_features = feature_vector.toarray()\n",
        "features_counts = np.sum(data_features, axis=0)\n",
        "feature_counts = pd.DataFrame({'features': features, 'counts': features_counts})"
      ],
      "metadata": {
        "id": "2BsCQfuWvsdH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "top_features_counts = features_counts_df.sort_values('counts', ascending=False).head(15)\n",
        "top_features_counts\n",
        "top_features_counts\n",
        "\n"
      ],
      "metadata": {
        "id": "IV3RGIZmvx3g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "english_stop_words = stopwords.words('english')"
      ],
      "metadata": {
        "id": "_OFuNF0BwH4z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['trtbps'][0:10]\n"
      ],
      "metadata": {
        "id": "JqwaxAMewSG0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "X_train, X_test, y_train, y_test = train_test_split(df['trtbps'],\n",
        "df['restecg'], test_size=0.2, random_state=42)\n",
        "vectorizer = CountVectorizer()\n",
        "X_train_vectorized = vectorizer.fit_transform(X_train)\n",
        "X_test_vectorized = vectorizer.transform(X_test)\n",
        "model = SVC()\n",
        "model.fit(X_train_vectorized, y_train)\n",
        "y_pred = model.predict(X_test_vectorized)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "report = classification_report(y_test, y_pred)\n",
        "5\n",
        "print(\"Accuracy: \", accuracy)\n",
        "print(\"Classification Report:\\n\", report)"
      ],
      "metadata": {
        "id": "FNNzdUgiLGKn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, cmap='Blues', fmt='d')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.xlabel('Predicted Labels')\n",
        "plt.ylabel('True Labels')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "_aOQKDjxGTwA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "X_train, X_test, y_train, y_test = train_test_split(df['trtbps'],df['restecg'], test_size=0.2, random_state=42)\n",
        "vectorizer = CountVectorizer()\n",
        "X_train_vectorized = vectorizer.fit_transform(X_train)\n",
        "X_test_vectorized = vectorizer.transform(X_test)\n",
        "model = RandomForestClassifier()\n",
        "model.fit(X_train_vectorized, y_train)\n",
        "y_pred = model.predict(X_test_vectorized)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "report = classification_report(y_test, y_pred)\n",
        "print(\"Accuracy: \", accuracy)\n",
        "print(\"Classification Report:\\n\", report)"
      ],
      "metadata": {
        "id": "FPNUNEhRGaFJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "sns.histplot(df['thalachh'])\n",
        "plt.title('thalachh')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "jI3HOzqNHhmU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.countplot(data=df, x='restecg')\n",
        "plt.title('Sentiment Anaysis')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "trkZu64jH2R0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(12, 5))\n",
        "plt.hist(features_counts_df['counts'], bins=50, range=(0, 5000))\n",
        "plt.xlabel('Frequency of Words')\n",
        "plt.ylabel('Density')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "N_wG2cOKH-mq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "j2b5zFk5IFgy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}